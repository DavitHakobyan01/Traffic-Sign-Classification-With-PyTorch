{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d75db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bdec745",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9989c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize([50, 50]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a03df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(r'C:\\Users\\Asus\\Desktop\\datasets\\GTSRB\\GTSRB\\Final_Training\\Images', transform=data_transform)\n",
    "# val_dataset = datasets.ImageFolder(r'C:\\Users\\Asus\\Desktop\\datasets\\GTSRB\\GTSRB\\Final_Test\\Images', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5314c70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[600][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b79b1f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50, 50])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6651b014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31367"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05f3c7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31367"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad600a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43f60090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[23000][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7fb1966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x234b1e5ec10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[23000][0].permute(1, 2, 0), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f0d3b",
   "metadata": {},
   "source": [
    "# Could not find data of sign names, so had to write manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5ea2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0: 'speed limit 20 km/h',\n",
    "    1: 'speed limit 30 km/h',\n",
    "    2: 'speed limit 50 km/h',\n",
    "    3: 'Speed limit (60km/h)',\n",
    "    4: 'Speed limit (70km/h)',\n",
    "    5: 'Speed limit (80km/h)',\n",
    "    6: 'End of speed limit (80km/h)',\n",
    "    7: 'Speed limit (100km/h)',\n",
    "    8: 'Speed limit (120km/h)',\n",
    "    9: 'No passing',\n",
    "    10: 'No passing for vechiles over 3.5 metric tons',\n",
    "    11: 'Right-of-way at the next intersection',\n",
    "    12: 'Priority road',\n",
    "    13: 'Yield',\n",
    "    14: 'Stop',\n",
    "    15: 'No vechiles',\n",
    "    16: 'Vechiles over 3.5 metric tons prohibited',\n",
    "    17: 'No entry',\n",
    "    18: 'General caution',\n",
    "    19: 'Dangerous curve to the left',\n",
    "    20: 'Dangerous curve to the right',\n",
    "    21: 'Double curve',\n",
    "    22: 'Bumpy road',\n",
    "    23: 'Slippery road',\n",
    "    24: 'Road narrows on the right',\n",
    "    25: 'Road work',\n",
    "    26: 'Traffic signals',\n",
    "    27: 'Pedestrians',\n",
    "    28: 'Children crossing',\n",
    "    29: 'Bicycles crossing',\n",
    "    30: 'Beware of ice/snow',\n",
    "    31: 'Wild animals crossing',\n",
    "    32: 'End of all speed and passing limits',\n",
    "    33: 'Turn right ahead',\n",
    "    34: 'Turn left ahead',\n",
    "    35: 'Ahead only',\n",
    "    36: 'Go straight or right',\n",
    "    37: 'Go straight or left',\n",
    "    38: 'Keep right',\n",
    "    39: 'Keep left',\n",
    "    40: 'Roundabout mandatory',\n",
    "    41: 'End of no passing',\n",
    "    42: 'End of no passing by vechiles over 3.5 metric tons'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0761f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'End of no passing')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(val_dataset[2000][0].permute(1, 2, 0), cmap=\"gray\")\n",
    "plt.title(class_names[val_dataset[2000][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09189163",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader_batch = next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc719fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  1,  8, 28, 15,  8,  1, 38,  7,  2, 26,  6, 17, 12,  3, 13, 13, 12,\n",
       "        15, 33, 33,  4,  8, 29, 35, 12,  7, 41, 23,  1, 10, 13, 26, 38,  3, 18,\n",
       "         8,  1, 13,  5,  5,  5, 31,  1, 18,  9, 37, 18,  2, 40, 16, 11,  1, 13,\n",
       "         9, 34, 13,  5, 20, 26, 40, 18,  1, 18])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = training_loader_batch\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff54cc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50, 50])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a6a0215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28,  5,  4, 10, 26, 13,  1, 38, 15, 37, 19, 26, 25, 15, 11, 26, 14, 18,\n",
       "         3,  4, 30, 33, 29,  5, 35, 11, 12, 25,  7, 11, 10, 35, 34,  4,  1, 13,\n",
       "        28,  3,  3, 13, 15, 13, 25, 34,  9, 23, 25,  1, 33,  2, 13, 12, 33, 17,\n",
       "         0, 24,  7, 27,  4,  5, 15, 20, 28,  2])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader_batch = next(iter(validation_loader))\n",
    "images, labels = val_loader_batch\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0683129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import flatten\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, \n",
    "                               kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, \n",
    "                               kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 25, \n",
    "                               kernel_size = 3, stride = 1, padding = 0)\n",
    "        self.linear1 = nn.Linear(225, 120)\n",
    "        self.linear2 = nn.Linear(120, 80)\n",
    "        self.linear3 = nn.Linear(80, 43)\n",
    "        self.sigmoid = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce4e66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4af6979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 46, 46]             456\n",
      "              ReLU-2            [-1, 6, 46, 46]               0\n",
      "         AvgPool2d-3            [-1, 6, 23, 23]               0\n",
      "            Conv2d-4           [-1, 16, 19, 19]           2,416\n",
      "              ReLU-5           [-1, 16, 19, 19]               0\n",
      "         AvgPool2d-6             [-1, 16, 9, 9]               0\n",
      "            Conv2d-7             [-1, 25, 7, 7]           3,625\n",
      "              ReLU-8             [-1, 25, 7, 7]               0\n",
      "         AvgPool2d-9             [-1, 25, 3, 3]               0\n",
      "           Linear-10                  [-1, 120]          27,120\n",
      "             ReLU-11                  [-1, 120]               0\n",
      "           Linear-12                   [-1, 80]           9,680\n",
      "             ReLU-13                   [-1, 80]               0\n",
      "           Linear-14                   [-1, 43]           3,483\n",
      "================================================================\n",
      "Total params: 46,780\n",
      "Trainable params: 46,780\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.34\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 0.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad29c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "abfac87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "training loss: 2.1299, training accuracy: 40.6319 \n",
      "validation loss: 0.9348, validation accuracy: 70.5177 \n",
      "epoch:  2\n",
      "training loss: 0.6173, training accuracy: 80.9864 \n",
      "validation loss: 0.4797, validation accuracy: 84.8125 \n",
      "epoch:  3\n",
      "training loss: 0.3604, training accuracy: 89.1797 \n",
      "validation loss: 0.3083, validation accuracy: 90.5254 \n",
      "epoch:  4\n",
      "training loss: 0.2551, training accuracy: 92.3263 \n",
      "validation loss: 0.2245, validation accuracy: 93.8536 \n",
      "epoch:  5\n",
      "training loss: 0.1833, training accuracy: 94.3826 \n",
      "validation loss: 0.2011, validation accuracy: 94.2744 \n",
      "epoch:  6\n",
      "training loss: 0.1460, training accuracy: 95.5845 \n",
      "validation loss: 0.1506, validation accuracy: 96.2127 \n",
      "epoch:  7\n",
      "training loss: 0.1048, training accuracy: 96.9363 \n",
      "validation loss: 0.1362, validation accuracy: 96.5315 \n",
      "epoch:  8\n",
      "training loss: 0.0919, training accuracy: 97.1881 \n",
      "validation loss: 0.1524, validation accuracy: 95.7536 \n",
      "epoch:  9\n",
      "training loss: 0.0766, training accuracy: 97.6376 \n",
      "validation loss: 0.1031, validation accuracy: 97.3476 \n",
      "epoch:  10\n",
      "training loss: 0.0599, training accuracy: 98.1796 \n",
      "validation loss: 0.1079, validation accuracy: 97.2456 \n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "running_loss_history = []\n",
    "running_corrects_history = []\n",
    "val_running_loss_history = []\n",
    "val_running_corrects_history = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "    \n",
    "    for inputs, labels in training_loader: \n",
    "        inputs = inputs.to(device) #GPU\n",
    "        labels = labels.to(device) #GPU\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    else: \n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in validation_loader:\n",
    "                val_inputs = val_inputs.to(device) #GPU\n",
    "                val_labels = val_labels.to(device) #GPU\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                \n",
    "                _, val_preds = torch.max(val_outputs, 1)\n",
    "                val_running_loss += val_loss.item()\n",
    "                val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
    "          \n",
    "        epoch_loss = running_loss/len(training_loader)\n",
    "        epoch_acc = running_corrects.float()/len(train_dataset)*100\n",
    "        running_loss_history.append(epoch_loss)\n",
    "        running_corrects_history.append(epoch_acc)\n",
    "        \n",
    "        val_epoch_loss = val_running_loss/len(validation_loader)\n",
    "        val_epoch_acc = val_running_corrects.float()/len(val_dataset)*100\n",
    "        val_running_loss_history.append(val_epoch_loss)\n",
    "        val_running_corrects_history.append(val_epoch_acc)\n",
    "    \n",
    "    print('epoch: ', (e+1))\n",
    "    print('training loss: {:.4f}, training accuracy: {:.4f} '.format(epoch_loss, epoch_acc.item()))\n",
    "    print('validation loss: {:.4f}, validation accuracy: {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a670ef40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 12630\n",
       "    Root location: C:\\Users\\Asus\\Desktop\\datasets\\GTSRB\\GTSRB\\Final_Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=[50, 50], interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = datasets.ImageFolder(r'C:\\Users\\Asus\\Desktop\\datasets\\GTSRB\\GTSRB\\Final_Test', transform=data_transform)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d741f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e2a57cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 50, 50])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader_batch = next(iter(test_loader))\n",
    "images, labels = test_loader_batch\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6c41e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(images[30:31]).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5e1c4c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, preds = torch.max(out, 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "358017b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21ca30abbe0>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[30].permute(1, 2, 0), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2162fa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No entry'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[preds.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80196c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
